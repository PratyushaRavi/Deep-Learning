{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day5_MLP_HousePricePrediction_Project.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YRtoRuKzB8B_"},"source":["# Predicting House Price using Keras\n","\n","In this tutorial we will build a MLP network to predict the house price."]},{"cell_type":"markdown","metadata":{"id":"5bdg8bqcEl57"},"source":["# About the dataset\n","\n","The dataset contains 11 columns and 1460 rows:\n","\n","1. Lot Area (in sq ft)\n","2. Overall Quality (scale from 1 to 10)\n","3. Overall Condition (scale from 1 to 10)\n","4. Total Basement Area (in sq ft)\n","5. Number of Full Bathrooms\n","6. Number of Half Bathrooms\n","7. Number of Bedrooms above ground\n","8. Total Number of Rooms above ground\n","9. Number of Fireplaces\n","10. Garage Area (in sq ft).\n","\n","The last column (column k) tells us whether the price of the house is above or below a certain median value. ( 0 or 1 )\n","\n","You can download the dataset from [here](https://github.com/josephlee94/intuitive-deep-learning/blob/master/Part%201:%20Predicting%20House%20Prices/housepricedata.csv)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2zOh3-QCN8HV"},"source":["We will use the following steps to build the neural network model.\n","1. Load the dataset\n","2. Define Keras Model\n","3. Compile Keras Model\n","4. Fit Keras Model\n","5. Evaluate Keras Model\n","6. Make Predictions\n","7. Check accuracy and loss of the model"]},{"cell_type":"markdown","metadata":{"id":"HK0RFCYSO8x3"},"source":["#Python Libraries\n","\n","\n","We will use the following Python libraries for building the model\n","\n","* Pandas\n","* sklearn\n","* keras\n","* matplotlib\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8Oe7CnAXeJ2d"},"source":["### Pandas\n","Pandas is a Python library which is used to analyze datasets.It has functions for analyzing, cleaning, exploring, and manipulating data.Pandas gives you answers about the data. Like:\n","\n","*Is there a correlation between two or more columns?\n","* What is average value?\n","* Max value?\n","* Min value?\n","Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called cleaning the data.\n","\n","The source code for Pandas is located at this github repository https://github.com/pandas-dev/pandas"]},{"cell_type":"markdown","metadata":{"id":"xrxCnS2YfvLx"},"source":["### Sklearn\n","\n","Rather than focusing on loading, manipulating and summarising data, Scikit-learn library is focused on modeling the data. Let's see what libraries from sklearn we will be using in this project:\n","\n","* preprocessing in sklearn ( MinMaxScaler() )\n","    * As we are dealing with lots of data and that data is in raw form, before inputting that data to machine learning algorithms, we need to convert it into meaningful data. This process is called preprocessing the data. Scikit-learn has package named preprocessing for this purpose . We will be using \"MinMaxScaler()\" from preprocessing to scale the features (parameters).Scaling of feature vectors is important, because the features should not be synthetically large or small.\n","\n","* splitting the dataset ( train_test_split() )\n","   \n","   * To check the accuracy of our model, we can split the dataset into two pieces-a training set and a testing set. Use the training set to train the model and testing set to test the model. After that, we can evaluate how well our model did. We will be using \" train_test_split()\" function of scikit-learn to split the dataset. \n","\n","The following github repository contains the source code for sklearn :https://github.com/scikit-learn/scikit-learn\n"]},{"cell_type":"markdown","metadata":{"id":"ANSNnpqliq5K"},"source":["### Keras\n","Keras is a powerful and easy-to-use free open source Python library for developing and evaluating deep learning models.Keras leverages various optimization techniques to make high level neural network.Let us quickly see what libraries from keras would we be using:\n","\n","* Sequential\n","\n","   * The core idea of Sequential API is simply arranging the Keras layers in a sequential order and so, it is called Sequential API. Most of the ANN also has layers in sequential order and the data flows from one layer to another layer in the given order until the data finally reaches the output layer\n","\n","* Dense \n","   \n","   * Dense layer is the regular deeply connected neural network layer. It is most common and frequently used layer. Dense layer does the below operation on the input and return the output.\n","\n","output = activation(dot(input, kernel) + bias)\n","where ,\n","  * input represent the input data\n","  * kernel represent the weight data\n","  * dot represent numpy dot product of all input and its corresponding weights\n","  * bias represent a biased value used in machine learning to optimize the model\n","  * activation represent the activation function."]},{"cell_type":"markdown","metadata":{"id":"GKiWFDJRmbX2"},"source":["### Matplotlib\n"," Matplotlib is one of the most popular Python packages used for data visualization. It is used for making 2D plots from data in arrays\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hcFY87g3z3Vk","executionInfo":{"status":"ok","timestamp":1614772547326,"user_tz":-330,"elapsed":111741,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"f0aa54ed-d884-40c2-d7d9-551d88de463e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OVnZeIW_zXdd"},"source":["import pandas as pd                      #This means that I want to refer to code in the package ‘pandas’, by referring to it with the name pd\n","from sklearn import preprocessing         #This means I want to use the code in ‘preprocessing’ within the sklearn package\n","from sklearn.model_selection import train_test_split    #used to split the data into training and testing from sklearn \n","from keras.models import Sequential     # imorting the sequential  from keras library. \n","from keras.layers import Dense            #importing dense model from keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6qwf5KPzqZR"},"source":["# 1. Load the dataset\n","\n","You can download the dataset from [here](https://github.com/josephlee94/intuitive-deep-learning/blob/master/Part%201:%20Predicting%20House%20Prices/housepricedata.csv)"]},{"cell_type":"code","metadata":{"id":"ObFxylgdDf3f"},"source":["                     \n","df = pd.read_csv('/content/drive/MyDrive/datasets/deep learning/housepricedata.csv')    #This means that we will read the csv file ‘housepricedata.csv’ and store it in the variable ‘df’"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vN_8G5kDFFcr"},"source":["## 1.1 Exploring the dataset"]},{"cell_type":"code","metadata":{"id":"tiqlFLjoETX3","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1614772755304,"user_tz":-330,"elapsed":5933,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"ca88274c-e7b2-4763-fee2-f1f395117c26"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>FullBath</th>\n","      <th>HalfBath</th>\n","      <th>BedroomAbvGr</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>Fireplaces</th>\n","      <th>GarageArea</th>\n","      <th>AboveMedianPrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8450</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>856</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>548</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9600</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1262</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>460</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11250</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>920</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>608</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9550</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>756</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>642</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14260</td>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>1145</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>836</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1455</th>\n","      <td>7917</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>953</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>460</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1456</th>\n","      <td>13175</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>1542</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>500</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1457</th>\n","      <td>9042</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>1152</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>252</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1458</th>\n","      <td>9717</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1078</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>240</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1459</th>\n","      <td>9937</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1256</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>276</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1460 rows × 11 columns</p>\n","</div>"],"text/plain":["      LotArea  OverallQual  ...  GarageArea  AboveMedianPrice\n","0        8450            7  ...         548                 1\n","1        9600            6  ...         460                 1\n","2       11250            7  ...         608                 1\n","3        9550            7  ...         642                 0\n","4       14260            8  ...         836                 1\n","...       ...          ...  ...         ...               ...\n","1455     7917            6  ...         460                 1\n","1456    13175            6  ...         500                 1\n","1457     9042            7  ...         252                 1\n","1458     9717            5  ...         240                 0\n","1459     9937            5  ...         276                 0\n","\n","[1460 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"T1w51-afFP-6"},"source":["We have our input features in the first ten columns:\n","\n","1. Lot Area (in sq ft)\n","2. Overall Quality (scale from 1 to 10)\n","3. Overall Condition (scale from 1 to 10)\n","4. Total Basement Area (in sq ft)\n","5. Number of Full Bathrooms\n","6. Number of Half Bathrooms\n","7. Number of Bedrooms above ground\n","8. Total Number of Rooms above ground\n","9. Number of Fireplaces\n","10. Garage Area (in sq ft)\n","\n","In our last column, we have the feature that we would be predicting i.e. whether the price of the house is above or below the median value ,1 for yes and 0 for no.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vpDqC5hQ0Zr7"},"source":["# 1.2 Preprocessing\n","In this step we will explore the dataset and clean the dataset.\n","\n","\n"," \n","\n"]},{"cell_type":"markdown","metadata":{"id":"oQGRfDL2BYPt"},"source":["We will complete the following in this step\n","* Read the CSV (comma separated values) file and convert them to arrays.\n","* Split our dataset into input features and the label.\n","* Scale the data so that the input features have similar orders of magnitude.\n","* Split our dataset into the training set, the validation set and the test set."]},{"cell_type":"markdown","metadata":{"id":"IhQyQLMKGLVG"},"source":["We have to convert the values from the dataset into arrays for procesing so that we can apply various mathematical functions and hence it is easier to work on it.\n","\n","To convert our dataframe into an array, we just store the values of df (by accessing df.values) into the variable ‘dataset’. To see what is inside this variable ‘dataset’, simply type ‘dataset’"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_hrWwXJ2FPqK","executionInfo":{"status":"ok","timestamp":1614772764064,"user_tz":-330,"elapsed":1037,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"9615a1ad-c9bc-4944-c2f6-305072fdcdf7"},"source":["dataset = df.values\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 8450,     7,     5, ...,     0,   548,     1],\n","       [ 9600,     6,     8, ...,     1,   460,     1],\n","       [11250,     7,     5, ...,     1,   608,     1],\n","       ...,\n","       [ 9042,     7,     9, ...,     2,   252,     1],\n","       [ 9717,     5,     6, ...,     0,   240,     0],\n","       [ 9937,     5,     6, ...,     0,   276,     0]])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"p_vRYvGqGkbA"},"source":["We now split our dataset into input features (X) and the feature we wish to predict (Y). To do that split, we simply assign the first 10 columns of our array to a variable called X and the last column of our array to a variable called Y."]},{"cell_type":"code","metadata":{"id":"QvnWxY-BEjdF"},"source":["X = dataset[:,0:10] #Everything before the comma refers to the rows of the array and everything after the comma refers to the columns of the arrays.\n","Y = dataset[:,10]  #Since we’re not splitting up the rows, we put ‘:’ before the comma. This means to take all the rows in dataset and put it in X.\n"," #We want to extract out the first 10 columns, and so the ‘0:10’ after the comma means take columns 0 to 9 and put it in X (we don’t include column 10). Our columns start from index 0, so the first 10 columns are really columns 0 to 9.\n","#We then assign the last column of our array to Y:"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GlpERSUexu1k"},"source":["Most of the times, your dataset will contain features highly varying in magnitudes, units and range.  The features with high magnitudes will weigh in a lot more than features with low magnitudes. To suppress this effect, we need to bring all features to the same level of magnitudes. This can be achieved by scaling.\n","\n","For this we will be using \"MinMaxScaler()\" from preprocessing to scale the features.This estimator scales and translates each feature individually such that it is in the given range on the training set i.e between 0 and 1."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPSbimyEG1Sy","executionInfo":{"status":"ok","timestamp":1614772771106,"user_tz":-330,"elapsed":1046,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"aa91ca02-61c4-4381-851b-3efe4a21c42a"},"source":["        \n","min_max_scaler = preprocessing.MinMaxScaler()\n","X_scale = min_max_scaler.fit_transform(X)\n","X_scale\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.0334198 , 0.66666667, 0.5       , ..., 0.5       , 0.        ,\n","        0.3864598 ],\n","       [0.03879502, 0.55555556, 0.875     , ..., 0.33333333, 0.33333333,\n","        0.32440056],\n","       [0.04650728, 0.66666667, 0.5       , ..., 0.33333333, 0.33333333,\n","        0.42877292],\n","       ...,\n","       [0.03618687, 0.66666667, 1.        , ..., 0.58333333, 0.66666667,\n","        0.17771509],\n","       [0.03934189, 0.44444444, 0.625     , ..., 0.25      , 0.        ,\n","        0.16925247],\n","       [0.04037019, 0.44444444, 0.625     , ..., 0.33333333, 0.        ,\n","        0.19464034]])"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"R6kWOFdlHIeJ"},"source":["from sklearn.model_selection import train_test_split   #used to split the data into training and testing"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfxOn1qTuKaS"},"source":[" we split the dataset into training and testing to scale the features."]},{"cell_type":"code","metadata":{"id":"0e4Pm0KaALq1"},"source":["X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)  #your val_and_test size will be 30% of the overall dataset."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BwXKvpw8AiPS"},"source":["the above code will store the split data into the first four variables on the left of the equal sign.\n","\n","Since we want a separate validation set and test set, we can use the same function to do the split again on val_and_test:"]},{"cell_type":"code","metadata":{"id":"mWo5VuwjAhkq"},"source":["X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UeqrofCOA0Br"},"source":["In summary, we now have a total of six variables for our datasets we will use:\n","\n","*  X_train (10 input features, 70% of full dataset)\n","*  X_val (10 input features, 15% of full dataset)\n","*  X_test (10 input features, 15% of full dataset)\n","*  Y_train (1 label, 70% of full dataset)\n","*  Y_val (1 label, 15% of full dataset)\n","*  Y_test (1 label, 15% of full dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zwqHEcwAvrQ","executionInfo":{"status":"ok","timestamp":1614772784718,"user_tz":-330,"elapsed":1108,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"9600aee5-6a09-46ea-9047-c8aa88482de4"},"source":["print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)  # to see the dimension of each variable"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7NT1MQWBNTd"},"source":["the training set has 1022 data points while the validation and test set has 219 data points each. The X variables have 10 input features, while the Y variables only has one feature to predict."]},{"cell_type":"markdown","metadata":{"id":"u96tIYRO1ubX"},"source":["# 2. Define keras model"]},{"cell_type":"markdown","metadata":{"id":"MXhxER3sCh0A"},"source":["The sequential API allows you to create models layer-by-layer.\n","\n","The dense layer is a neural network layer that is connected deeply, which means each neuron in the dense layer receives input from all neurons of its previous layer.the dense layer performs a matrix-vector multiplication.\n"]},{"cell_type":"markdown","metadata":{"id":"sCk67kVwBw4z"},"source":["we want to have these layers:\n","\n","* Hidden layer 1: 32 neurons, ReLU activation\n","* Hidden layer 2: 32 neurons, ReLU activation\n","* Output Layer: 1 neuron, Sigmoid activation\n","\n"]},{"cell_type":"code","metadata":{"id":"LcKpbS9rCDev"},"source":["# define the keras model\n","model = Sequential([\n","    Dense(32, activation='relu', input_shape=(10,)),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid'),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oZGyyxEiEByG"},"source":["This says that we will store our model in the variable ‘model’, and we’ll describe it sequentially (layer by layer) in between the square brackets.\n","\n","We have our first layer as a dense layer with 32 neurons, ReLU activation and the input shape is 10 since we have 10 input features.\n","\n","Our second layer is also a dense layer with 32 neurons, ReLU activation.We do not have to describe the input shape since Keras can infer from the output of our first layer\n","\n","Our third layer is a dense layer with 1 neuron, sigmoid activation."]},{"cell_type":"markdown","metadata":{"id":"DO6-y7omEaua"},"source":["# 3. Compile Keras Model :\n","\n"," The compilation is the final step in creating a model.It    configures the model for training.\n"," \n"," For this we define 3 things: loss function,optimizer and metrics\n","\n","* Loss-  Loss function is used to find error or deviation in the learning process\n","* optimization - Optimization is an important process which optimize the input weights by comparing the prediction and the loss function.\n","* metrics - Metrics is used to evaluate the performance of the model.it is used to track accuracy on top of the loss function\n"]},{"cell_type":"code","metadata":{"id":"ZPDVYAM7D7VE"},"source":["#compiling the model\n","model.compile(optimizer='sgd',         #the optimizer used is stochastic gradient descent\n","              loss='binary_crossentropy',  #the loss function used is binary cross entropy\n","              metrics=['accuracy'])         #the metrics used is accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TJW1whqT4oF0"},"source":["There are various different types of loss functions, optimizers and metrics that are used. You can go through [this link](https://www.tutorialspoint.com/keras/keras_model_compilation.htm) to see all of them."]},{"cell_type":"markdown","metadata":{"id":"bOrDoo-eFBia"},"source":["# 4. Fit keras model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"G6aU8ldx6hgF"},"source":["Model fitting is a measure of how well a model generalizes to similar data to that on which it was trained. A model that is well-fitted produces more accurate outcomes.During the fitting process, you run an algorithm on data for which you know the target variable, known as “labeled” data, and produce a model. Then, you compare the outcomes to real, observed values of the target variable to determine their accuracy. Next, you use that information to adjust the algorithm’s standard parameters to reduce the level of error, making it more accurate in uncovering patterns and relationships between the rest of its features and the target. You repeat this process until the algorithm finds the optimal parameters that produce valid, practical, applicable insights for your problem."]},{"cell_type":"code","metadata":{"id":"qtOLAYbEEtXp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614772879322,"user_tz":-330,"elapsed":10213,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"e48fd311-7ba8-4f97-f2cc-c07cdb1005cb"},"source":["hist = model.fit(X_train, Y_train,\n","          batch_size=32, epochs=100,\n","          validation_data=(X_val, Y_val))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","32/32 [==============================] - 0s 5ms/step - loss: 0.2367 - accuracy: 0.8924 - val_loss: 0.2758 - val_accuracy: 0.8721\n","Epoch 2/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.8973 - val_loss: 0.2729 - val_accuracy: 0.8721\n","Epoch 3/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.8992 - val_loss: 0.2743 - val_accuracy: 0.8721\n","Epoch 4/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.8992 - val_loss: 0.2606 - val_accuracy: 0.8721\n","Epoch 5/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9012 - val_loss: 0.2646 - val_accuracy: 0.8721\n","Epoch 6/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.8982 - val_loss: 0.2798 - val_accuracy: 0.8767\n","Epoch 7/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.8992 - val_loss: 0.2661 - val_accuracy: 0.8676\n","Epoch 8/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.8963 - val_loss: 0.2638 - val_accuracy: 0.8721\n","Epoch 9/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.8992 - val_loss: 0.2633 - val_accuracy: 0.8721\n","Epoch 10/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9022 - val_loss: 0.2591 - val_accuracy: 0.8721\n","Epoch 11/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.8992 - val_loss: 0.2626 - val_accuracy: 0.8676\n","Epoch 12/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.8982 - val_loss: 0.2656 - val_accuracy: 0.8676\n","Epoch 13/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.8933 - val_loss: 0.2700 - val_accuracy: 0.8721\n","Epoch 14/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8953 - val_loss: 0.2683 - val_accuracy: 0.8721\n","Epoch 15/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9012 - val_loss: 0.2680 - val_accuracy: 0.8676\n","Epoch 16/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8982 - val_loss: 0.2684 - val_accuracy: 0.8721\n","Epoch 17/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.8982 - val_loss: 0.2676 - val_accuracy: 0.8676\n","Epoch 18/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.8973 - val_loss: 0.2649 - val_accuracy: 0.8676\n","Epoch 19/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2356 - accuracy: 0.8992 - val_loss: 0.2587 - val_accuracy: 0.8676\n","Epoch 20/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.8963 - val_loss: 0.2642 - val_accuracy: 0.8721\n","Epoch 21/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.8953 - val_loss: 0.2631 - val_accuracy: 0.8721\n","Epoch 22/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9012 - val_loss: 0.2618 - val_accuracy: 0.8721\n","Epoch 23/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8963 - val_loss: 0.2628 - val_accuracy: 0.8721\n","Epoch 24/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.8963 - val_loss: 0.2628 - val_accuracy: 0.8721\n","Epoch 25/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.8992 - val_loss: 0.2751 - val_accuracy: 0.8721\n","Epoch 26/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.8963 - val_loss: 0.2641 - val_accuracy: 0.8676\n","Epoch 27/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.8982 - val_loss: 0.2601 - val_accuracy: 0.8721\n","Epoch 28/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.8982 - val_loss: 0.2556 - val_accuracy: 0.8721\n","Epoch 29/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2361 - accuracy: 0.8992 - val_loss: 0.2575 - val_accuracy: 0.8721\n","Epoch 30/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8982 - val_loss: 0.2702 - val_accuracy: 0.8721\n","Epoch 31/100\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.9012 - val_loss: 0.2633 - val_accuracy: 0.8721\n","Epoch 32/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.8973 - val_loss: 0.2581 - val_accuracy: 0.8676\n","Epoch 33/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.8963 - val_loss: 0.2731 - val_accuracy: 0.8721\n","Epoch 34/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8982 - val_loss: 0.2757 - val_accuracy: 0.8767\n","Epoch 35/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.9002 - val_loss: 0.2596 - val_accuracy: 0.8721\n","Epoch 36/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.8982 - val_loss: 0.2644 - val_accuracy: 0.8676\n","Epoch 37/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9012 - val_loss: 0.2616 - val_accuracy: 0.8721\n","Epoch 38/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.8982 - val_loss: 0.2705 - val_accuracy: 0.8721\n","Epoch 39/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.8982 - val_loss: 0.2697 - val_accuracy: 0.8721\n","Epoch 40/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2332 - accuracy: 0.8992 - val_loss: 0.2669 - val_accuracy: 0.8676\n","Epoch 41/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2346 - accuracy: 0.8973 - val_loss: 0.2628 - val_accuracy: 0.8676\n","Epoch 42/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.8973 - val_loss: 0.2618 - val_accuracy: 0.8721\n","Epoch 43/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.8973 - val_loss: 0.2578 - val_accuracy: 0.8676\n","Epoch 44/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.8953 - val_loss: 0.2609 - val_accuracy: 0.8721\n","Epoch 45/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.8963 - val_loss: 0.2701 - val_accuracy: 0.8721\n","Epoch 46/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.8982 - val_loss: 0.2577 - val_accuracy: 0.8676\n","Epoch 47/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.8953 - val_loss: 0.2583 - val_accuracy: 0.8676\n","Epoch 48/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.8943 - val_loss: 0.2742 - val_accuracy: 0.8767\n","Epoch 49/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.8973 - val_loss: 0.2591 - val_accuracy: 0.8721\n","Epoch 50/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2340 - accuracy: 0.8982 - val_loss: 0.2639 - val_accuracy: 0.8630\n","Epoch 51/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2334 - accuracy: 0.8963 - val_loss: 0.2595 - val_accuracy: 0.8721\n","Epoch 52/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.8982 - val_loss: 0.2631 - val_accuracy: 0.8676\n","Epoch 53/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.8953 - val_loss: 0.2719 - val_accuracy: 0.8767\n","Epoch 54/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.8992 - val_loss: 0.2752 - val_accuracy: 0.8767\n","Epoch 55/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.8973 - val_loss: 0.2619 - val_accuracy: 0.8676\n","Epoch 56/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.8992 - val_loss: 0.2559 - val_accuracy: 0.8767\n","Epoch 57/100\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.8973 - val_loss: 0.2586 - val_accuracy: 0.8721\n","Epoch 58/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.9002 - val_loss: 0.2825 - val_accuracy: 0.8813\n","Epoch 59/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2343 - accuracy: 0.8982 - val_loss: 0.2646 - val_accuracy: 0.8630\n","Epoch 60/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.8963 - val_loss: 0.2710 - val_accuracy: 0.8767\n","Epoch 61/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.8982 - val_loss: 0.2815 - val_accuracy: 0.8767\n","Epoch 62/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.8953 - val_loss: 0.2625 - val_accuracy: 0.8676\n","Epoch 63/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.9012 - val_loss: 0.2701 - val_accuracy: 0.8721\n","Epoch 64/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.8982 - val_loss: 0.2692 - val_accuracy: 0.8721\n","Epoch 65/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.8982 - val_loss: 0.2575 - val_accuracy: 0.8676\n","Epoch 66/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2324 - accuracy: 0.9002 - val_loss: 0.2590 - val_accuracy: 0.8721\n","Epoch 67/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9012 - val_loss: 0.2561 - val_accuracy: 0.8721\n","Epoch 68/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.8992 - val_loss: 0.2677 - val_accuracy: 0.8721\n","Epoch 69/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.8943 - val_loss: 0.2726 - val_accuracy: 0.8767\n","Epoch 70/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.8982 - val_loss: 0.2593 - val_accuracy: 0.8721\n","Epoch 71/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9031 - val_loss: 0.2589 - val_accuracy: 0.8721\n","Epoch 72/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.8963 - val_loss: 0.2847 - val_accuracy: 0.8813\n","Epoch 73/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9012 - val_loss: 0.2557 - val_accuracy: 0.8721\n","Epoch 74/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2326 - accuracy: 0.8973 - val_loss: 0.2593 - val_accuracy: 0.8721\n","Epoch 75/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.8953 - val_loss: 0.2677 - val_accuracy: 0.8721\n","Epoch 76/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2309 - accuracy: 0.9012 - val_loss: 0.2655 - val_accuracy: 0.8676\n","Epoch 77/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.8963 - val_loss: 0.2564 - val_accuracy: 0.8676\n","Epoch 78/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.8943 - val_loss: 0.2646 - val_accuracy: 0.8630\n","Epoch 79/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.8982 - val_loss: 0.2672 - val_accuracy: 0.8676\n","Epoch 80/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.8992 - val_loss: 0.2776 - val_accuracy: 0.8767\n","Epoch 81/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.8982 - val_loss: 0.2609 - val_accuracy: 0.8676\n","Epoch 82/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.8992 - val_loss: 0.2603 - val_accuracy: 0.8676\n","Epoch 83/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.8992 - val_loss: 0.2691 - val_accuracy: 0.8767\n","Epoch 84/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.8992 - val_loss: 0.2566 - val_accuracy: 0.8630\n","Epoch 85/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.8973 - val_loss: 0.2650 - val_accuracy: 0.8676\n","Epoch 86/100\n","32/32 [==============================] - 0s 4ms/step - loss: 0.2305 - accuracy: 0.8943 - val_loss: 0.2671 - val_accuracy: 0.8676\n","Epoch 87/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.8963 - val_loss: 0.2621 - val_accuracy: 0.8676\n","Epoch 88/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.8943 - val_loss: 0.2577 - val_accuracy: 0.8721\n","Epoch 89/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8943 - val_loss: 0.2679 - val_accuracy: 0.8767\n","Epoch 90/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9002 - val_loss: 0.2623 - val_accuracy: 0.8676\n","Epoch 91/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9041 - val_loss: 0.2651 - val_accuracy: 0.8676\n","Epoch 92/100\n","32/32 [==============================] - 0s 2ms/step - loss: 0.2320 - accuracy: 0.8953 - val_loss: 0.2633 - val_accuracy: 0.8630\n","Epoch 93/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.8992 - val_loss: 0.2558 - val_accuracy: 0.8676\n","Epoch 94/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.8973 - val_loss: 0.2537 - val_accuracy: 0.8767\n","Epoch 95/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.8982 - val_loss: 0.2649 - val_accuracy: 0.8676\n","Epoch 96/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.8982 - val_loss: 0.2814 - val_accuracy: 0.8813\n","Epoch 97/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.8982 - val_loss: 0.2665 - val_accuracy: 0.8676\n","Epoch 98/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.8992 - val_loss: 0.2545 - val_accuracy: 0.8767\n","Epoch 99/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.8992 - val_loss: 0.2558 - val_accuracy: 0.8676\n","Epoch 100/100\n","32/32 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.9002 - val_loss: 0.2655 - val_accuracy: 0.8676\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8XWfIzZbFNJe"},"source":["The function is called ‘fit’ as we are fitting the parameters to the data. We have to specify what data we are training on, which is X_train and Y_train. Then, we specify the size of our batch and how long we want to train it for (epochs). Lastly, we specify what our validation data is so that the model will tell us how we are doing on the validation data at each point. This function will output a history, which we save under the variable hist."]},{"cell_type":"markdown","metadata":{"id":"HRkjuL932Nq-"},"source":["# 5. Evaluate keras model\n","\n","We have trained our neural network on the entire dataset and we can evaluate the performance of the network on the test dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOoZmsntFGmW","executionInfo":{"status":"ok","timestamp":1614772884392,"user_tz":-330,"elapsed":1185,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"1b99be5c-727e-4320-c978-064625efc4a2"},"source":["model.evaluate(X_test, Y_test)[1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["7/7 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.8995\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.8995434045791626"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"GHLnc5wyFleA"},"source":["The reason why we have the index 1 after the model.evaluate function is because the function returns the loss as the first element and the accuracy as the second element. To only output the accuracy, simply access the second element (which is indexed by 1, since the first element starts its indexing from 0)."]},{"cell_type":"markdown","metadata":{"id":"RFr95gwz295e"},"source":["# 6. Making predictions\n","We can adapt the above example and use it to generate predictions on the training dataset, pretending it is a new dataset "]},{"cell_type":"code","metadata":{"id":"y5BwFSmLFf_5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614772894297,"user_tz":-330,"elapsed":1359,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"b7a2d6e4-3b32-4c7d-f829-f298d65f4d1f"},"source":["predictions = model.predict(X)  # using the model to predict on training data i.e. x and \n","                                # storing it in the variable \"predictions\"\n","                                \n","predictions[:5]    #viewing only the first 5 model predictions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"5A_u2GRo-o55"},"source":["So our model predicted 1(above median value) for the first 5 inputs. If we compare our predicted output with the output from training dataset we can see that the fourth input has the value 0(below median price) whereas our model predicted 1 that is beacuse our model achieved an accuracy of about 89-90 percent. For our model to predict more accurate results we have to train our model with more data. You can go through \n","[this](https://machinelearningmastery.com/improve-deep-learning-performance/) link to see what other parameters needs to changed in order to achieve greater accuracy.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fflc0v2g4VPG"},"source":["# 7. Check the accuracy of the model\n","###Training loss and validation loss\n"," One can learn a lot about neural networks and deep learning models by observing their performance over time during training.Training loss is the error on the training set of data. Validation loss is the error after running the validation set of data through the trained network. \n","\n","By doing this we can see how well our algorithm models the dataset. If the predictions are totally off, the loss function will output a higher number. If they’re pretty good, it’ll output a lower number. As we can see , as the number of epochs increases the value of loss decreases"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"8eJmGxu33Nwp","executionInfo":{"status":"ok","timestamp":1613563742971,"user_tz":-330,"elapsed":1705,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"f6db3419-4eb0-4529-fca8-4de3c7aa8d54"},"source":["import matplotlib.pyplot as plt\n","plt.plot(hist.history['loss'])\n","plt.plot(hist.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'], loc='upper right')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"b5xaB6Vr6MWD"},"source":["The first two lines says that we want to plot the loss and the val_loss. The third line specifies the title of this graph, “Model Loss”. The fourth and fifth line tells us what the y and x axis should be labelled respectively. The sixth line includes a legend for our graph, and the location of the legend will be in the upper right. And the seventh line shows the output. Similarly we can do for accuracy as well"]},{"cell_type":"markdown","metadata":{"id":"9pUE-gMs4n0K"},"source":["### Training accuracy and validation accuracy\n","\n","To have a visual understanding on how the model trained between the epochs, let's try to plot the graph of training and validation accuracy. It is similar to how we visualised  the loss functions. The only difference being here, as the number of epochs inceases the accuracy of the model increases as well."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"jwiLhcig4LXX","executionInfo":{"status":"ok","timestamp":1613563951066,"user_tz":-330,"elapsed":2109,"user":{"displayName":"Aditya Gupta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-ab1CMuB52ERgqQYD99rSaa9VUTDRjYvYHpkx5A=s64","userId":"01588507944926124910"}},"outputId":"1fb6557b-ec97-4ac9-d2c9-3ff8f36e21af"},"source":["plt.plot(hist.history['accuracy'])\n","plt.plot(hist.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'], loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfr48c8zJZ2aQofQe1NEioooKlYsoOC6inV17a5r+9lXv7urqOyurhUXVlcRwYINFAQEQQUE6SUESEJLgQSSkDIz5/fHvQmTEGCATCbJPO/Xa16Z25/L1fvMOefec8QYg1JKqfDlCHUASimlQksTgVJKhTlNBEopFeY0ESilVJjTRKCUUmFOE4FSSoU5TQQqLIhIsogYEXEFsO54EVlUE3EpVRtoIlC1johsE5ESEUmoNH+FfTNPDk1kStVPmghUbbUVGFc2ISK9gZjQhVM7BFKiUep4aSJQtdV7wPV+0zcA//VfQUQaich/RSRLRLaLyOMi4rCXOUVkgohki0gqcHEV204SkV0iskNEnhMRZyCBicjHIrJbRPJE5AcR6em3LFpEXrLjyRORRSISbS87Q0QWi0iuiKSLyHh7/nwRucVvHxWqpuxS0J0ishnYbM/7h72P/SKyXETO9FvfKSKPicgWETlgL28jIq+JyEuVzmWmiNwfyHmr+ksTgaqtfgIaikh3+wY9Fni/0jr/AhoBHYBhWInjRnvZrcAlQH9gADC60raTAQ/QyV7nfOAWAvMN0BlIAn4F/ue3bAJwKjAEaAo8BPhEpJ293b+ARKAfsDLA4wFcDpwO9LCnl9r7aAp8AHwsIlH2sgewSlMXAQ2Bm4BCYAowzi9ZJgAj7O1VODPG6Ec/teoDbMO6QT0O/BUYCXwHuAADJANOoATo4bfdH4D59vfvgdv9lp1vb+sCmgHFQLTf8nHAPPv7eGBRgLE2tvfbCOuH1UGgbxXrPQp8eoR9zAdu8ZuucHx7/+ccI459ZccFNgKjjrDeeuA8+/tdwNehvt76Cf1H6xtVbfYe8APQnkrVQkAC4Aa2+83bDrSyv7cE0istK9PO3naXiJTNc1Rav0p26eR5YAzWL3ufXzyRQBSwpYpN2xxhfqAqxCYiDwI3Y52nwfrlX9a4frRjTQGuw0qs1wH/OImYVD2hVUOq1jLGbMdqNL4I+KTS4mygFOumXqYtsMP+vgvrhui/rEw6VokgwRjT2P40NMb05NiuBUZhlVgaYZVOAMSOqQjoWMV26UeYD1BAxYbw5lWsU95NsN0e8BBwNdDEGNMYyLNjONax3gdGiUhfoDvw2RHWU2FEE4Gq7W7GqhYp8J9pjPEC04DnRaSBXQf/AIfaEaYB94hIaxFpAjzit+0u4FvgJRFpKCIOEekoIsMCiKcBVhLJwbp5/5/ffn3Au8DLItLSbrQdLCKRWO0II0TkahFxiUi8iPSzN10JXCkiMSLSyT7nY8XgAbIAl4g8iVUiKPMO8BcR6SyWPiISb8eYgdW+8B4wwxhzMIBzVvWcJgJVqxljthhjlh1h8d1Yv6ZTgUVYjZ7v2sveBmYDv2E16FYuUVwPRADrsOrXpwMtAgjpv1jVTDvsbX+qtPxBYDXWzXYv8HfAYYxJwyrZ/MmevxLoa2/zClZ7xx6sqpv/cXSzgVnAJjuWIipWHb2MlQi/BfYDk4Bov+VTgN5YyUApxBgdmEapcCIiZ2GVnNoZvQEotESgVFgRETdwL/COJgFVRhOBUmFCRLoDuVhVYBNDHI6qRbRqSCmlwpyWCJRSKszVuRfKEhISTHJycqjDUEqpOmX58uXZxpjEqpbVuUSQnJzMsmVHeppQKaVUVURk+5GWadWQUkqFOU0ESikV5jQRKKVUmAtqIhCRkSKyUURSROSRKpa3E5G5IrLKHpyjdTDjUUopdbigJQK7u97XgAuxBtMYJyI9Kq02AfivMaYP8CxW3/NKKaVqUDBLBAOBFGNMqjGmBJiK1X2vvx5YA4gAzKtiuVJKqSALZiJoRcUeETM4NGhImd+AK+3vVwANyrrL9Scit4nIMhFZlpWVFZRglVIqXIX6PYIHgVftQbx/wOra11t5JWPMW8BbAAMGDNA+MZQ6Hpu+hYylh6Y7Dod2Q0IXj6p1gpkIdlBxhKjWHBo9CgBjzE7sEoGIxAFXGWNygxiTUuGlpBCm3wgl+VgDmBn4dQrcuwrcUcfaWoWJYFYNLQU6i0h7EYkAxgIz/VcQkQQRKYvhUQ4NKqKUOl571kFJQcV5m2ZZSeD6mfB0Lvz+M8jfA6umhiZGVSsFrURgjPGIyF1Yoyk5gXeNMWtF5FlgmTFmJnA28FcRMVhVQ3cGKx6l6rWCbHhrGPS5Bka9emj+mhkQ1xySz7CmO5wNLfrBj/+E/r8HhzMU0dZahSUeUrMK2JZTwMGSQ7XUCQ0i6ZgQR6sm0TgdUuW2Xp8hY18hqVkFbMnKJzW7gNSsfDIPFFe5fkyEkzM6JXJejyT6tWlSYb+FJR6mLU3n69W7GdwxnusHtyM+LrJ6T9ZPneuGesCAAUb7GlJ1js8H3mJwRx973TL5meApOny+ww0NmoP43ZB+eRu+ftBadt8qaNgSDu6DCV3gtFtgpN+T2Ws/g49vgDFToOflVcfqOQgRsYHHWkOMMUycs5kfU7J59KJunNquaUDb+d+ks/KLuaBHcxrFuMuX/5q2j4enr2JzZv5R9xPhctA+PpYOidbHGEjNKiA1O59t2YWUeH3l6zaOcdMhIZYWjaLLL5XLV4LHEQFATn4JS7ftxeMzNI5x06VZAzomxhLtdvHJigxyC0tpnxDL1uwCotwO7uxRzGUjhtMusdFx/qtZRGS5MWZAVctC3VisVP2XvRlm3Gz9av/DDxCbcOxttsyD96q4SZe58m3oc/Wh6dXToWFrOLALlrwGFzwP678Abwn0Hl1x2+6XQtOOsOgV6DGqYkLZmwqf3AaZ6+GiCdB3bPnyHbkHWbQ5i6tOaY3LGVitsjEGkap/QQP4fIYvVu2kY2IcvVpVvMH9lJpDQbGHc7olle/j3/O38I+5m4mJcHLV60u4ZkAbHrygK42irZt65oEi5q7PZM76PSzfvg+vz/qh6/GZ8u8Af4/dwGMXdeeK/q2YsmQb//f1epo1jOLB87vQITGO9gmxxEUeuj3u3l9EalZ++a/9jbsP8O26PQjQNj6GDglxDO+WRMeEODtJxNE0NqLiyc59Fn55B26dCwmdAcg7WMqCTVn8uDmbLVn5zFqzm9yDpZzXvRl/GNaBU9s1JWV3Lps/fZ4RGyaxWu6n3dgnAvq3Px5aIlAqWIzdMDvrUXBFWvX3nc+Ha96vePOtwsGpNyIpc0gb8BgdEuJwOf3WX/wva99//AkcDshNg4m94ZwnIGsDbPwG7l8D026AvHS4+9fDj7d8MnxxL1z/uVVdZAz8NtUqVYgTEjrBjuXQ6yq4+GXmpZVw/0cryS0sZUT3JF699hSi3EevVlq4OYt7PlzB8K5JPHpRdxIbVKzaWLMjj8c/W8PK9Fyi3A5e/92pDO+WBMDHy9J55JPVeH2Gs7ok8uxlPVmYks0Tn61hVL+WPHd5L179PoVJi7bi8R1+D+uYGMsZnRKIirBidDmEtk1j6JAYh0Pgua/WsyItl1aNo9mRe5AR3ZN4aUy/CqWEYym1f/27A0mKW3+AKZcBBlr2h5u/A2fVxyrx+Ihw2fvMy4BP/gDbF1HU5TK4ZCJRDQ97wj4gRysRaCJQ6mTs3Qpf3AO7Vx++zPigKA86nE3RJa9RsHwa8T8+Q9Y5E4gcOJ6GUVXfCBavT6P/RwP41DOUxzy3EBfpYljXRM7r3ozhXZNotOVzq4Qx9gPodrH1y37O03Dvb1CcD28MhdNuhaXvwLCHKD7zYQQ5dHMB8BRjJvbBHMzFuKIBH87iPGg3FK5406paWvQKZt7/4REX+V43TofgdjooKvXicgixkS4cAgYrj4hYzyUBlHh9FBR7cQj47GXRbicOEbzG4PHBzJIB/DviRu44vw8f/pLGhl0HmDCmL3v2FzHpmyW80fg9enjWU1Tqpewu5XZaxy07jtdnKPX63cME3A45Yj1++aXBuuEWlfqIdDmIdDsQZ4RVhdbrqkMrlhbBh2Nh18qj7u8w8Z3hsn9BUjc4mAuvD7V+DAx7CD79A5z1Zzjncasa7pc34df/wpjJkNj10D6yN8M7I8DngYtehL7jjvkD4mi0akip6mYMrPoIvnoQxGFVv/g1vPqMoaDYyyba8k7+GSyYuIaDJZ15392TfnP/H6PnRjDxjivp2rzBoW18hlfnpbD5+8kMcRcz6PLbmRTbjznr9/Dduky+WrULp0MY1K4Fb8W0JmbhK0jXi2D1dAqTTuHFRQV0SGzAtR3Pw7n0bQA+8wzmiefmEOF0cP3gZK4f3A6vMUxZvI1NBbcyuPRnsNsy051taNXpj1zfoBUuh4NVHW5h8vKm9MqZTdekGE7vEI/LIezOLmDh5ixiHC4cDiG/qBSfgbhIF22axhDpcvBbRi5JDSI5p1szikq9/JSaw668Q+0dia5Cxjq/55qG23C2mcRlfQdx23+Xc99HKxnhWM73MW8T6ylF+lyNz+dk+fZ9eLyGM7skIn43eaf9OV4CRNqfctuXwMx7oOUp0LS9NW/uM5A6D/pfB+6YwHZufFY7zFvD4PznIP1nq8rulu+g1alW6WDhS9C8j1Uy2zLXKoXNuAVumQuuCPCWwie3Wv9t/eEHiO94AmcZOC0RKBWgzXsO4DPQLraUqNkPWk/ktB0CV75JYUxLFm7OZu76PazKyCM1u4ASj1V10KxhJCO6N+OUtk2IK97N8HlXsMHTgnuinufTu4bRJDaCEo+PB6at5MtVu/gy4VV6yFYc96+zqn6wksRvGbnMWb+Hr1bt4ozcz3nO/R8WdHqYYSl/56nSG/ifGYnHZzg3JoVJvifZ4uzIuQV/YWineCJdTr7fkEm024nPGEq8Ps7r3owLejbH6RAMhs9X7mT+xiy6t2hI39aN+GhZOglxkTxxSQ8u69uywr/Fws1Z/GtuCgkNIuiQYNWHL96Sw6KULIpKfZzbzao+irarZowxLEnNwSFCx8Q4EuIikG0LrWqPgixoOwgvDtIz95JcuBrTvA9y1SRI7FJzFzg33frlntQNxn8N2xZa7TSn3QoXTzi+fR3YA5//EVLmWNPDH4dhf7a+F+2HN86A3O3girbac+KawUe/gzMegBFPwffPwQ8vwtXvQY/LquX0tGpIqRPk8xnmb8rkjQWp/LJ1L6fJBiZG/JtmspcPoq9jRvRoPDhIycyn2OOjQZSL05Kb0jExlo6JcfRs2YherRpWbDBdPR1m3MxE7xh+aXsLr193Knd98CsLN2fz1IjmjF98PnL67dYN4ggxfb9mO6d9ehYxvnwcYpgyeBZXntmfjbsP8NaCLQza8gobIvsw7LIbuLRPC0SETXsOMHnxNpwijB+aTMfEuAr7NcYwa81unvliHZkHirh+cDIPnN/liFVYVTlY4mVLVj7dmjcIrEG5cC/MeQqyNh2al3yGVYXiCt7jkke06mP45BYYcjesngGRcXDbAogIsDTgz+eDZZMgcx1c+CI4/SpgdvwKi/8JZz96qDpo5t3w63tw3jNWVV/fa+Hy16rltEATgVInZMmWHJ75Yi0bdh+gTUMX/2j5Lf23vUteVEveTnyM9c5Dv1bbNo3hvB7NOC25acW6+COZcQu+NZ9wRdFTbIvqTn6xh79e2ZurmQNf3mfdfFr2O/o+fngRvn8Ob4fhOK//rMKi3XlFNIx2ERNx/LW/hSUecvJLaNP0BG5+9cH0m6zSnsMFt8yxGndrQnG+VVLYtxUat4M7foTIBsfeLkDaRqDUURQUe/hq9S4aRrnplBRLbKSLF2dt5JMVO2jdJJq3LmnCiPVP4Ni2DPpeS+OLXuDPJ/s/6EUTcGxfwn8i3+bcgr/wxnVDOK9HM5g8w2pobNH32Ps47RZY8wnO0/9w2KLmjU68+4iYCBcxTcP41nDxS7Bvu/VyXk0lAbBKH1e9A5/fBZf9s1qTwLFoiUCFLWMMs9fu4bmZq+iS/zNxHGrMdDrg3O7NuKCtwb3wBash+JKJ0OvKo+zxOG1dCFMuxdvjcpzdL4HSg1b1wNmPWB+lqpGWCJSqZM2OPF76diMbN67nzdg36R2x9vCVNtufskcqG7c5fJ2T0f5MOON+nItehnWfWvMcLug9pnqPo9QxaCJQR1YbuxrwloLPG1DPmbvzipizfg8bdu+ndZMYOiTEEl24i5nLUvg1bR+nRWznjbjJRDiAi1+FtoMO34k4oEn78qd3qt2Ip+DUG6zzAqs6oEHz4BxLqSPQRKCqZgxM+z1kLIPbF0JcUqgjsm6W/7kIinLh1nlWnWoVFm3O5oXZG1iVkQdYz7fnF3u43jmbZ91TOBMOPUDe/DS48i1o2qFGTqFKTZJDd2yl0ESgjmT5ZNjwpfV95t0wbupJvdVYLRa8ABm/ALBj2gO8Fnc3ThHuPrcTSQ2sEsLM33byp2kradMkhodGduW87s3olBRHfvpqYqdMZW/iUBoMHo/b4bBeEOp8fsXH+pQKQ/p/gDpcdgrMfgw6DLdulLMfheX/gQE3hS6mtJ8xCyewtNFIVue6uXnLR+T62jHHewpzVmzm/ZbTabdnDud7vax1Cy5XSxxtJkKzTuAppsFXf4SohjS9bgrEJYbuPJSqhTQRqIq8pfDpbeCMgMv/bfVlv/lbmP3/IPksqzOyGnKwxMvW7AK27tzDabNuoNgbz537ruGCPu3Iz9jMayXvsmdYVxzfPkbTnVl87B1Gk/gkRvRohmPzLOut0MF3Wa/871kN4z7SJKBUFTQRqEM8JTDrYavXyTFTrI7HAC5/HV4fbPV9cvO3FXtN3LkSvnvyUL/5MfFw8cvQsMWhdQqyrRLGkHugea8Khyz1+li6bS9LfttA73Uvstrblve5GB8O8g6WEkMRL7lfJ965h8/7v8WcCy61eojMnAxvDqP5NzdjmiSzuO8H5Pg6MWZYR+uN1uGPwrePwxJ7kJZTb4SuI4P3b6dUHabvEShL9mar06tdK61f0ZW7NygbzGTYwzD8MWte8QF440zrb9kNPu1n6+mb6z6xnrQxBj66zmpviO9sdaBlv66/ftd+bp68lK4HljDB/SZNJB8HPlLjTuHTdk/Qyr2fS1KeJDY/De+IZ3GdcU/FmFZPt17VP/sRiGpY9Xlt/AY2fg0j/1a7nn5SqoZpFxPqyIyxusCd9Qi4oqyuc7tfUvW6n95hjXV702xoM9B6A3LF+3Dj19BuiLXO0knw1QMw8u8w6HZr3zPvhl6jYc308g68lm7byx2Tf+Rhx/8Y4/sGX1JPHKMnQcZS+OZha6St0gKraurKNw8NtaiUOiH6QpmqWuFeqy/99V9Yg5Nc/kbFKp3KLvw7bF9kjWB19qOw4j2rt8SyJABWg/Km2VZHYo3bwjePQPuzyDzvX7gdTWiy9G2WuE7lrwvzmB7xKsm+dBh0J44RT1mdjCV1t3r0/OJeq2rqohcgukmw/yWUCmtaIggn2xdDzhbru6cIFr5sdQE84ikYdGdgL01tXwyTL7YaYFv0hZvnWP2n+8vPhH8PhsJsiGrE8ou+4pqp6Th9xXwe8QTNZS+xUowztimOK96ATudW/7kqpSrQEkG4KymwGmuXT644P6ELXDs1sA7OyrQbAmc9BD+9bo2bWzkJgPXy2ahX4eMbKR75EvfPyqZVk2j+fEE/MvNepdP8cdBhBI7LXwts/F6lVFBpiaC+2/UbTL8ZclKsPtYH3kr5gIINWpz4y1Se4mP3F+8p5i+ztjBp0Vam3jaIQR3ssVZLD4I7+sSOq5Q6IVoiCFeFe2HyJdbTMtd/Dh2GVd++q0gCP6Zk89dv1nNhrxZcd3o7tmQX8u6PW7luUNtDSQA0CShVy2giqM+WvgPF+62nfJr1COqhfk3bx63/XUaEy8GLszfy73kpxEa6aNkomkcu7B7UYyulTo4mgvqqpBB+fgO6jAx6Etiwez83/mcpiQ0i+fj2wWQfKOHthal8u3Y3b/z+VOIi9T8zpWoz/T+0vlrxPhTmwBn3B/Uw6XsL+f2kX4hyO3j/5tNJahBFUoMoXrnmGMMsKqVqDU0E9ZG3FBb/C9oMqrqP/WpS6vVx14crKCr1MuOOIeE7xq1SdVyQRttQIbXmE8hLC3pp4OXvNvFbei5/u7IPXZrV3PiqSqnqpSWCumr/Tvjxn1By4PBlqQsgsbvVhXSQLNqczRsLtjBuYBsu7nOUt5GVUrWeJoK6aN3nMPMe63n8ql7IEiec+2S1Dq+Yub+IxVtyMBh8PvjbrA10TIzjyUt6VtsxlFKhoYmgNjqYC2tmWGPzVrbzV/jtQ2jZH66aBPEdgxqKx+tjypLtvPLdJvKLPeXzYyKcTLlxINERzqAeXykVfJoIaqMf/wGLXq56mTisjt6GP1ZxXIBq8vxX6/jit10kJ8TQMTGOFWm5rNu1n2FdEnnw/K40iLL+k2kSG0Gj6Oo/vlKq5mkiqG2Msbpr7nA2XPXu4ctdERAZnIbZDbv3M2nRVnq3akSxx8eXq3YRF+ni9d+dwshezZFQj1mslAoKTQS1TcZSyE2Dsx+D2Phjr1+N/v7NBuIiXUy5aSCNYyIo64dKE4BS9Zs+PlrbrP7YGiCm28U1etjFW7KZtzGLPw7vROMYq0dREdEkoFQY0BJBbeL1WO8AdLngyEMvVoOiUi8T52xGBMYPSSYxLpK/fbOBlo2iGD8kOWjHVUrVTpoIapOt863BXHqPCdoh0nIK+eMHy1mzYz8OgXcWpjKwfVNWZeQxYUxfotz6FJBS4UYTQSj9+h5s+ApG/hWatofVMyCyEXQ6r1oPU1TqZWt2ASvTc/m/r9cjwNvXD6BrswZMWpTKR8vS6dmyIVf0b1Wtx1VK1Q2aCEJl9xprkHdvCWxbBBc8b40d3HMUuKOOa1fFHi+z1uwmyu2kY2IsrZvE8Ft6LnPW7+H7DZmkZhdQNv5Qr1YN+fe1p9I23uoX6JlRvfjTBV1xiOB0aHuAUuEoqIlAREYC/wCcwDvGmL9VWt4WmAI0ttd5xBjzdTBjqhVKi+CTWyGqMfxuGsx6zBpEHqDX6OPa1Y8p2Tzx2RpSswsOW+Z2CoM6xHNp35Z0SIyjQ0Is3Zo3wOWs+IxAwyh9H0CpcBa0RCAiTuA14DwgA1gqIjONMev8VnscmGaMeV1EegBfA8nBiqnW+P4vkLkOrv3YekN4/Jfw40TYuRLanxXQLgqKPTz26Wo+X7mTdvExTLphAPFxkaRm5ZO2t5AuzRpwZucEGuhNXil1DMEsEQwEUowxqQAiMhUYBfgnAgOUPR7TCNgZxHhqh9T5sORVGHAzdLE7hXM44cw/BbyLYo+X299fzo8p2dx7bmfuOLtjeSNvvzaNgxC0Uqo+C2YiaAWk+01nAKdXWudp4FsRuRuIBUZUtSMRuQ24DaBt27bVHmiNObgPPr0D4jvB+c+d0C48Xh/3friShZuzmTCmL6NPbV3NQSqlwk2oG4vHAZONMS+JyGDgPRHpZYzx+a9kjHkLeAtgwIABJgRxnjxj4MsHoCATxn4HEYEN4pKSeYC/z9pIi0ZRdEiIZUV6LrPW7ubJS3poElBKVYtgJoIdQBu/6db2PH83AyMBjDFLRCQKSAAygxhXaKz+GNZ+Auc8Dq1OCWgTj9fH/R/9RkpmPi6HcMDu/fPecztz0xntgxmtUiqMBDMRLAU6i0h7rAQwFri20jppwLnAZBHpDkQBWUGMKTRy0+CrB6HN6TA08FHD3lm0ldU78nj12v5c3LsFWfnF5Bd5aJ8QG8RglVLhJmiJwBjjEZG7gNlYj4a+a4xZKyLPAsuMMTOBPwFvi8j9WA3H401ZT2f1xe41MP0mMF644k1wBvZPviUrn5e/28QFPZtxce8WiIg9MHyQ41VKhZ2gthHY7wR8XWnek37f1wFDgxlDyPh88PMbMOcpiG4CYz+w3h4OaFPDw9NXEe128pdRvbTjN6VUUIW6sbj++vpPsOxd6HIhjHq16iElq2CM4f++Xs+y7ft4aUxfkhoe31vGSil1vDQRBIPXA6umWZ3HXfk2BPiL3uP18cgnq5m+PIPrB7fjylO07x+lVPBpIgiGzLVQkg+dLwg4CRSVernrgxXMWb+H+0Z05t5zO2uVkFKqRmgiCIa0n6y/bQcFvMmTn69h7oY9/GVUT34/ODk4cSmlVBV0hLJgSFsCDVtD4zbHXhf4YVMW05ZlcMewjpoElFI1ThNBdTPGKhEEWBrIL/bw6Cer6ZgYyz3ndg5ycEopdTitGqpuuWlwYFfAieCFWRvYmXeQ6bcP0dHBlFIhoYmgugXYPmCM4avVu/jvku3cNLQ9p7ZrUgPBKaXU4TQRVLe0JRDZEJJ6lM/yeH1k55cAYDD8lJrDmwtS2bD7AJ2T4njwgi6hilYppTQRVLv0n6HNQGuMAdu9H63kq1W7KqzWpVkcL47uw6h+rYhwaVONUip0NBFUp4P7rJHHel1ZPquo1Mvc9XsY3jWR83s2B6B1k2jO6JSg7wkopWoFTQTVKf0X62/bweWzftm6l6JSH9cPSWZ416QQBaaUUkemdRLVKW0JONzQ8tB4A/M3ZhHhcjCofXwIA1NKqSPTRFCd0n6Clv0qjD42f1MmgzrEEx2hj4YqpWonTQTVJT/TaihuP6x8VvreQlKzCji7S2IIA1NKqaPTRFBd1n4Gxge9R5fPmr/JGmzt7K6aCJRStZcmguqy+mNo1guSupfPWrAxk7ZNY3RoSaVUraaJoDrs3QoZv0Cvq8pnFXu8LN6Sw7AuifqYqFKqVtNEUB3WzLD++iWCpVv3UVji1WohpVStp4mgOqyeDm0GQZN25bMWbMokwulgcEd9bFQpVbtpIjhZe9ZC1voKjcQlHh9frdrFoI7xxEToO3tKqdpNE8HJWv0xiBN6XlE+a9qydHbmFXHLGe1DGJhSSgVGE8HJMMZqH+g4HGITAKuR+LV5KZzStjFndk4IcYBKKXVsmghORtZGayCabpeUz5q2NJ1deUXcf14XfVpIKVUnaCI4GSlzrL+dzgWsnkeDDJUAABl0SURBVEZfm7eFAe2acEYnLQ0opeoGTQQnI2UOJHSFxm0B+GhpOrv3a2lAKVW3aCI4USWFsH0xdBoBWKWBf89PYWByU4boI6NKqTrkmIlARC4VEU0YlW3/EbzF0OkcAKb+ksae/cXcd15nLQ0opeqUQG7w1wCbReQFEekW7IDqjJQ54IqCdkPt0sAWTm/flCEdtW1AKVW3HDMRGGOuA/oDW4DJIrJERG4TkQZBj642S5kDyWeAO5oPfk4j80Ax943QQeiVUnVPQFU+xpj9wHRgKtACuAL4VUTuDmJstde+bZCTAp1GUFTq5fUFWxjUoal2J6GUqpMCaSO4TEQ+BeYDbmCgMeZCoC/wp+CGV0ulzLX+dhrB+z9tJ+tAMfdraUApVUcF0hHOVcArxpgf/GcaYwpF5ObghFXLpcyFRm0hvhPvLvqewR3iOb2DlgaUUnVTIFVDTwO/lE2ISLSIJAMYY+YGJararLQIti6ATueQV+RhZ16RdjWtlKrTAkkEHwM+v2mvPS88pXwHJfnQ/VLS9xYC0C4+5hgbKaVU7RVIInAZY0rKJuzvEcELqZZb/THEJED7s9meYyWCtk11KEqlVN0VSCLIEpHLyiZEZBSQHbyQarGi/bBpNvS6Epwutu8tAKCtlgiUUnVYII3FtwP/E5FXAQHSgeuDGlVtteEr8BRBL2sQmrScQhLiIoiL1MFnlFJ1VyAvlG0xxgwCegDdjTFDjDEpwQ+tZmzcfYDhE+aTeaDo2Cuv/tjqYK7NQAC25xTSpqmWBpRSdVtAP2VF5GKgJxBV1o+OMebZALYbCfwDcALvGGP+Vmn5K8BwezIGSDLGNA44+mqwbPtetmYXsCo9jxE9oo68Yn4WpM6HofeC/W+QtreQ05Kb1EygSikVJMdMBCLyBtZNejjwDjAav8dJj7KdE3gNOA/IAJaKyExjzLqydYwx9/utfzdWVxY1aleuVRLYllNw9BXXfQbGC73HANZIZDvzDtI2vnWwQ1RKqaAKpLF4iDHmemCfMeYZYDAQyGu0A4EUY0yq/aTRVGDUUdYfB3wYwH6r1c68g0AAiWD1x5DUE5r1ACBj30GMgXZaNaSUquMCSQRlleeFItISKMXqb+hYWmE1LJfJsOcdRkTaAe2B74+w/DYRWSYiy7KysgI4dOB25lqJoOxR0Cod2A3pP1tPC9nScvQdAqVU/RBIIvhCRBoDLwK/AtuAD6o5jrHAdGOMt6qFxpi3jDEDjDEDEhOr6S1eYwDYlWflua3ZRykRpC2x/nYcXj5re44+OqqUqh+OmgjsAWnmGmNyjTEzgHZAN2PMkwHsewfQxm+6tT2vKmOpyWqh1AXwcnd8ezawK68Ih1glg2JPlXkI0n4Cdww073No1t6DRLudJMZF1lDQSikVHEdNBMYYH1aDb9l0sTEmL8B9LwU6i0h7EYnAutnPrLySPdhNE2BJwFGfrJzNcGAX3hm3Yjwl9G7dGJ+x6v2rlLYEWp0KTvehWXsLaNs0RkcjU0rVeYFUDc0VkavkOO94xhgPcBcwG1gPTDPGrBWRZ/3fVMZKEFONsetqaoKnGAB35irudc0oH2N4W1XVQ8UHYPdqaDu4wuztOYVaLaSUqhcCeY/gD8ADgEdEirDeLjbGmIbH2tAY8zXwdaV5T1aafjrgaKuLx2oX2Nn2Uu7YPpPVceN4HdhWVYNxxjIwPmg7qHyWz2dI21vIsC7a66hSqu4L5M3iBsYYhzEmwhjT0J4+ZhKo1ewSwZwOj5Bukuj9y0MkRXmqLhGk/QTigNanlc/KPFBMscenTwwppeqFQF4oO6uq+ZUHqqlTPEXgjCS9wMFT5lam7H+OsXErWZHT/PB105ZAs54QdSj3HXpiSHsdVUrVfYFUDf3Z73sU1otiy4FzghJRTfAUgyuKnXlFpDUcAO52jCxZyGc5lXKe12NVDfX/XYXZ28vGIdCXyZRS9cAxE4Ex5lL/aRFpA0wMWkQ1wVMErkh25h6kZZNoaD+abgsnUlS8ixKPjwiXXWO2ZzWUFlRoHwDrZTKHQKsm0SEIXimlqlcgTw1VlgF0r+5AapRdItiVW0SLRtHQewwOvIx0/ETGPr8G47SfrL9tKiaC7XsLadk4GrfzRP75lFKqdgmkjeBfQNmjnQ6gH9YbxnWXpwjjiiTzQBEtG0VBUlcKm3TjspwlbMspoENinLVe2hKr2+lGFXvGSMsp0IZipVS9EchP2mVYbQLLsV76etgYc11Qowo2TzGlEoHPQMvGVvWO6TWaAY5NZKdvttYxxioRVHp/AKzup3V4SqVUfRFIY/F0oKisHyARcYpIjDHmKL201XKeIkqw3hJuYSeCmFPGwMLnaJo6E3xDYPE/IX/PYe0DP6fmsK+wlF6t6vYTtEopVSaQRDAXGAHk29PRwLfAkGAFFXSeYoqMlQhaNbYGo5Emyaxz9aBn1lfw/kZrEJpul0Cfayps+sqcTSQ2iOSqU3QcAqVU/RBI1VCUMaYsCWB/r9sV5J4iCn1WDmzR6NCTP2uajqCFJwPSf4FL/wHXvA8Rh6qAlmzJ4afUvdwxrCNRbmeNh62UUsEQSCIoEJFTyiZE5FTgCL2z1RGeYgp8LhpGuYj1G3h+V/IV/Ns7itJb5sOp48uHpAQwxvDKnE0kNYjk2tPb1nzMSikVJIFUDd0HfCwiO7H6GWoOXHP0TWo5TzEHPM7yhuIyrZol8WDpNVzobE37Spss2ZLDL1v38vSlPbQ0oJSqVwJ5oWyp3VV0V3vWRmNMaXDDCjJPMXmlTlomVkwEXZpZj40u2ZJD+4RDVULGGCbO2UyzhpGMHailAaVU/XLMqiERuROINcasMcasAeJE5I/BDy2IPEXklTho0SiqwuzerRrRu1Uj3l6Yitd3qFfs+Zuy+GXbXu4c3klLA0qpeieQNoJbjTG5ZRPGmH3ArcELKfiMp4j9VVQNiQi3D+vI1uwCZq/dDYDXZ/j7NxtoFx/D2NO0NKCUqn8CSQRO/0FpRMQJRAQvpOAznmKKcdOycdRhy0b2ak5yfAxvLNiCMYZPfs1gw+4D/PmCrof6IFJKqXokkDvbLOAjETlXRM7FGlv4m+CGFUTG4PBaicD/0dEyTofwh2EdWZWRx/cbMnn5u030bd2Ii3u3CEGwSikVfIEkgoeB74Hb7c9qrJfK6iZ7UJpiE3FYG0GZK/q3IrFBJHd/uIJdeUU8cmF3HZtYKVVvBTJCmQ/4GdiGNRbBOVhjENdN9jCVxbiJi6z6oakot5Obz2hPYYmXc7olMdge01gppeqjIz4+KiJdgHH2Jxv4CMAYM7xmQguSshIBbqIjjvwE0HWD2rElM587h3eqqciUUiokjvYewQZgIXCJMSYFQETur5GogsmvRBDlOnIiiIt08eKYvjUVlVJKhczRqoauBHYB80TkbbuhuO5XlNslAq8jEoej7p+OUkqdrCMmAmPMZ8aYsUA3YB5WVxNJIvK6iJxfUwFWO7tEYJyRIQ5EKaVqh0AaiwuMMR/YYxe3BlZgPUlUN9klAlyaCJRSCo5zzGJjzD5jzFvGmHODFVDQ2SUCXFU/OqqUUuEm/F6VtUsE4tZEoJRSEJaJoKxEoFVDSikFYZwInFoiUEopICwTgVU15HDX3V4ylFKqOoVhIrBLBJGaCJRSCsIyEVglAmeEVg0ppRSEZSKwSgQuTQRKKQWEZSKwSgTuCK0aUkopCGDw+vrGeIooMW6iI8Lu1JVSqkphVyLwlhy0eh49ShfUSikVTsIwERQdswtqpZQKJ+GXCEoPHnNQGqWUCidhlwh8JUUUGzfRbk0ESikF4ZgISosowU2UJgKllAKCnAhEZKSIbBSRFBF55AjrXC0i60RkrYh8EMx4wHpqSKuGlFLqkKA9QykiTuA14DwgA1gqIjONMev81ukMPAoMNcbsE5GkYMVTrrTYbiwOu8KQUkpVKZh3w4FAijEm1RhTAkwFRlVa51bgNWPMPgBjTGYQ47F47DYCLREopRQQ3ETQCkj3m86w5/nrAnQRkR9F5CcRGVnVjkTkNhFZJiLLsrKyTi4qbzHFRGhjsVJK2UJdP+ICOgNnA+OAt0WkceWV7OExBxhjBiQmJp7UAcVjVw1pIlBKKSC4iWAH0MZvurU9z18GMNMYU2qM2QpswkoMQePwFmtjsVJK+QlmIlgKdBaR9iISAYwFZlZa5zOs0gAikoBVVZQaxJhw+IopNloiUEqpMkFLBMYYD3AXMBtYD0wzxqwVkWdF5DJ7tdlAjoisA+YBfzbG5AQrJgCnV58aUkopf0HtgtMY8zXwdaV5T/p9N8AD9qdGOH0llEoELqcmAqWUgtA3FtcsY3CZEnzOyFBHopRStUZ4JQJ7UBpNBEopdUiYJQJrmEpNBEopdUiYJQKrRGA0ESilVLnwSgReOxG4NBEopVSZ8EoEdolAnFEhDkQppWqPMEsEVhuBuDURKKVUmTBLBFaJALdWDSmlVJkwSwRWicChJQKllCoXpokgOsSBKKVU7RFmicCqGnJGaIlAKaXKhFUiMKVWicAVoSUCpZQqE1aJwFNyEACnJgKllCoXXomg2EoErkhNBEopVSasEkGpnQjcmgiUUqpcWCWCsqqhiChNBEopVSasEoG3xGosjtQSgVJKlQuvRFB6kGLjIjLCHepQlFKq1girROArKaIYN9E6cL1SSpULr0Tg0USglFKVhVUiMCVFFBNBdIQmAqWUKuMKdQA1yXiKKDFuolyaCJRSqkxYJQI8xZTgpkFEWBWElAp7paWlZGRkUFRUFOpQgi4qKorWrVvjdgf+UExYJQLRNgKlwlJGRgYNGjQgOTkZEQl1OEFjjCEnJ4eMjAzat28f8HZh9dNYvMUU4yZKE4FSYaWoqIj4+Ph6nQQARIT4+PjjLvmEXSIoIQK3M6xOWykF9T4JlDmR8wyrO6LDW4xHIkIdhlJK1SphlQicvhI8Dk0ESqmalZOTQ79+/ejXrx/NmzenVatW5dMlJSVH3XbZsmXcc889QY0vrBqLnb5ivA4duF4pVbPi4+NZuXIlAE8//TRxcXE8+OCD5cs9Hg8uV9W34wEDBjBgwICgxhdWicDlK8GnJQKlwtozX6xl3c791brPHi0b8tSlPY9rm/HjxxMVFcWKFSsYOnQoY8eO5d5776WoqIjo6Gj+85//0LVrV+bPn8+ECRP48ssvefrpp0lLSyM1NZW0tDTuu+++aikthF8iiNASgVKqdsjIyGDx4sU4nU7279/PwoULcblczJkzh8cee4wZM2Ycts2GDRuYN28eBw4coGvXrtxxxx3H9c5AVcIqEbiNlgiUCnfH+8s9mMaMGYPTaT3OnpeXxw033MDmzZsREUpLS6vc5uKLLyYyMpLIyEiSkpLYs2cPrVu3Pqk4wqex2BgiKMG4tESglKodYmNjy78/8cQTDB8+nDVr1vDFF18c8V2AyMhD9zCn04nH4znpOMInEXjtlnlnVGjjUEqpKuTl5dGqVSsAJk+eXKPHDp9E4LGzq5YIlFK10EMPPcSjjz5K//79q+VX/vEQY0yNHvBkDRgwwCxbtuz4N8zPhAmd+bzVA4y69anqD0wpVWutX7+e7t27hzqMGlPV+YrIcmNMlc+hhl2JQFxaNaSUUv7CJhGYUisRONyaCJRSyl/YJAJPyUEAHBGaCJRSyl9QE4GIjBSRjSKSIiKPVLF8vIhkichK+3NLsGIpKbYTgZYIlFKqgqC9UCYiTuA14DwgA1gqIjONMesqrfqRMeauYMVRpuRgIbGAKzI62IdSSqk6JZglgoFAijEm1RhTAkwFRgXxeEdVViJwujURKKWUv2AmglZAut90hj2vsqtEZJWITBeRNlXtSERuE5FlIrIsKyvrhIIpLS4EwK0lAqVUDRs+fDizZ8+uMG/ixInccccdVa5/9tlnc0KPyZ+gUDcWfwEkG2P6AN8BU6payRjzljFmgDFmQGJi4gkdqNQuEWgiUErVtHHjxjF16tQK86ZOncq4ceNCFFFFwex0bgfg/wu/tT2vnDEmx2/yHeCFYAXjLbEeH3VHxgTrEEqpuuCbR2D36urdZ/PecOHfjrh49OjRPP7445SUlBAREcG2bdvYuXMnH374IQ888AAHDx5k9OjRPPPMM9UbV4CCWSJYCnQWkfYiEgGMBWb6ryAiLfwmLwPWBysYj50IIqI0ESilalbTpk0ZOHAg33zzDWCVBq6++mqef/55li1bxqpVq1iwYAGrVq0KSXxBKxEYYzwichcwG3AC7xpj1orIs8AyY8xM4B4RuQzwAHuB8cGKx1tqVQ1FROnjo0qFtaP8cg+msuqhUaNGMXXqVCZNmsS0adN466238Hg87Nq1i3Xr1tGnT58ajy2o4xEYY74Gvq4070m/748CjwYzhjI+u0QQpSUCpVQIjBo1ivvvv59ff/2VwsJCmjZtyoQJE1i6dClNmjRh/PjxR+x6OthC3VhcY9a3uIIRxS8QFR0X6lCUUmEoLi6O4cOHc9NNNzFu3Dj2799PbGwsjRo1Ys+ePeXVRqEQNiOU7Zc4UkxroiLD5pSVUrXMuHHjuOKKK5g6dSrdunWjf//+dOvWjTZt2jB06NCQxRU2d8W2TWO4sFdzot3OUIeilApTl19+Of5d/x9pAJr58+fXTEC2sEkE5/dszvk9m4c6DKWUqnXCpo1AKaVU1TQRKKXCQl0bjfFEnch5aiJQStV7UVFR5OTk1PtkYIwhJyeHqON8Xyps2giUUuGrdevWZGRkcKKdVtYlUVFRtG7d+ri20USglKr33G437du3D3UYtZZWDSmlVJjTRKCUUmFOE4FSSoU5qWut6CKSBWw/wc0TgOxqDKeuCMfzDsdzhvA873A8Zzj+825njKlyZK86lwhOhogsM8YMCHUcNS0czzsczxnC87zD8Zyhes9bq4aUUirMaSJQSqkwF26J4K1QBxAi4Xje4XjOEJ7nHY7nDNV43mHVRqCUUupw4VYiUEopVYkmAqWUCnNhkwhEZKSIbBSRFBF5JNTxBIOItBGReSKyTkTWisi99vymIvKdiGy2/zYJdazVTUScIrJCRL60p9uLyM/29f5IRCJCHWN1E5HGIjJdRDaIyHoRGRwm1/p++7/vNSLyoYhE1bfrLSLvikimiKzxm1fltRXLP+1zXyUipxzv8cIiEYiIE3gNuBDoAYwTkR6hjSooPMCfjDE9gEHAnfZ5PgLMNcZ0Buba0/XNvcB6v+m/A68YYzoB+4CbQxJVcP0DmGWM6Qb0xTr/en2tRaQVcA8wwBjTC3ACY6l/13syMLLSvCNd2wuBzvbnNuD14z1YWCQCYCCQYoxJNcaUAFOBUSGOqdoZY3YZY361vx/AujG0wjrXKfZqU4DLQxNhcIhIa+Bi4B17WoBzgOn2KvXxnBsBZwGTAIwxJcaYXOr5tba5gGgRcQExwC7q2fU2xvwA7K00+0jXdhTwX2P5CWgsIi2O53jhkghaAel+0xn2vHpLRJKB/sDPQDNjzC570W6gWYjCCpaJwEOAz56OB3KNMR57uj5e7/ZAFvAfu0rsHRGJpZ5fa2PMDmACkIaVAPKA5dT/6w1HvrYnfX8Ll0QQVkQkDpgB3GeM2e+/zFjPC9ebZ4ZF5BIg0xizPNSx1DAXcArwujGmP1BApWqg+natAex68VFYibAlEMvhVSj1XnVf23BJBDuANn7Tre159Y6IuLGSwP+MMZ/Ys/eUFRXtv5mhii8IhgKXicg2rCq/c7DqzhvbVQdQP693BpBhjPnZnp6OlRjq87UGGAFsNcZkGWNKgU+w/huo79cbjnxtT/r+Fi6JYCnQ2X6yIAKrcWlmiGOqdnbd+CRgvTHmZb9FM4Eb7O83AJ/XdGzBYox51BjT2hiTjHVdvzfG/A6YB4y2V6tX5wxgjNkNpItIV3vWucA66vG1tqUBg0Qkxv7vvey86/X1th3p2s4ErrefHhoE5PlVIQXGGBMWH+AiYBOwBfh/oY4nSOd4BlZxcRWw0v5chFVnPhfYDMwBmoY61iCd/9nAl/b3DsAvQArwMRAZ6viCcL79gGX29f4MaBIO1xp4BtgArAHeAyLr2/UGPsRqAynFKv3dfKRrCwjWU5FbgNVYT1Qd1/G0iwmllApz4VI1pJRS6gg0ESilVJjTRKCUUmFOE4FSSoU5TQRKKRXmNBEoVYmIeEVkpd+n2jpuE5Fk/x4llaoNXMdeRamwc9AY0y/UQShVU7REoFSARGSbiLwgIqtF5BcR6WTPTxaR7+2+4OeKSFt7fjMR+VREfrM/Q+xdOUXkbbtP/W9FJDpkJ6UUmgiUqkp0paqha/yW5RljegOvYvV6CvAvYIoxpg/wP+Cf9vx/AguMMX2x+gFaa8/vDLxmjOkJ5AJXBfl8lDoqfbNYqUpEJN8YE1fF/G3AOcaYVLtzv93GmHgRyQZaGGNK7fm7jDEJIpIFtDbGFPvtIxn4zliDiyAiDwNuY8xzwT8zpaqmJQKljo85wvfjUez33Yu21akQ00Sg1PG5xu/vEvv7YqyeTwF+Byy0v88F7oDyMZUb1VSQSh0P/SWi1OGiRWSl3/QsY0zZI6RNRGQV1q/6cfa8u7FGCvsz1qhhN9rz7wXeEpGbsX7534HVo6RStYq2ESgVILuNYIAxJjvUsShVnbRqSCmlwpyWCJRSKsxpiUAppcKcJgKllApzmgiUUirMaSJQSqkwp4lAKaXC3P8HHgPdI8N5gP0AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"kvZH3wNe-2pq"},"source":["Similar to what we did above in visualising the loss,the first two lines says that we want to plot the accuracy and the val_accuracy. The third line specifies the title of this graph, “Model accuruacy”. The fourth and fifth line tells us what the y and x axis should be labelled respectively. The sixth line includes a legend for our graph, and the location of the legend will be in the upper right. And the seventh line shows the output."]}]}